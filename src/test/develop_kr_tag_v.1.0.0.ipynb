{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08b8554",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kiwipiepy in /data/edutem/.pyenv/versions/3.11.3/envs/kr_tag/lib/python3.11/site-packages (0.19.0)\n",
      "Collecting kiwipiepy\n",
      "  Downloading kiwipiepy-0.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwipiepy-model<0.21,>=0.20\n",
      "  Downloading kiwipiepy_model-0.20.0.tar.gz (34.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /data/edutem/.pyenv/versions/3.11.3/envs/kr_tag/lib/python3.11/site-packages (from kiwipiepy) (4.66.5)\n",
      "Requirement already satisfied: numpy in /data/edutem/.pyenv/versions/3.11.3/envs/kr_tag/lib/python3.11/site-packages (from kiwipiepy) (1.26.4)\n",
      "Installing collected packages: kiwipiepy-model, kiwipiepy\n",
      "  Attempting uninstall: kiwipiepy-model\n",
      "    Found existing installation: kiwipiepy-model 0.19.0\n",
      "    Uninstalling kiwipiepy-model-0.19.0:\n",
      "      Successfully uninstalled kiwipiepy-model-0.19.0\n",
      "\u001b[33m  DEPRECATION: kiwipiepy-model is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for kiwipiepy-model ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: kiwipiepy\n",
      "    Found existing installation: kiwipiepy 0.19.0\n",
      "    Uninstalling kiwipiepy-0.19.0:\n",
      "      Successfully uninstalled kiwipiepy-0.19.0\n",
      "Successfully installed kiwipiepy-0.20.1 kiwipiepy-model-0.20.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/data/edutem/.pyenv/versions/3.11.3/envs/kr_tag/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade kiwipiepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1760661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kiwipiepy==0.18.1\n",
      "  Using cached kiwipiepy-0.18.1-cp311-cp311-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting kiwipiepy-model<0.19,>=0.18 (from kiwipiepy==0.18.1)\n",
      "  Using cached kiwipiepy_model-0.18.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy<2 in d:\\d_project\\anaconda3_envs\\test\\lib\\site-packages (from kiwipiepy==0.18.1) (1.26.4)\n",
      "Requirement already satisfied: tqdm in d:\\d_project\\anaconda3_envs\\test\\lib\\site-packages (from kiwipiepy==0.18.1) (4.66.4)\n",
      "Requirement already satisfied: colorama in d:\\d_project\\anaconda3_envs\\test\\lib\\site-packages (from tqdm->kiwipiepy==0.18.1) (0.4.6)\n",
      "Using cached kiwipiepy-0.18.1-cp311-cp311-win_amd64.whl (1.3 MB)\n",
      "Installing collected packages: kiwipiepy-model, kiwipiepy\n",
      "  Attempting uninstall: kiwipiepy-model\n",
      "    Found existing installation: kiwipiepy_model 0.19.0\n",
      "    Uninstalling kiwipiepy_model-0.19.0:\n",
      "      Successfully uninstalled kiwipiepy_model-0.19.0\n",
      "  Attempting uninstall: kiwipiepy\n",
      "    Found existing installation: kiwipiepy 0.19.0\n",
      "    Uninstalling kiwipiepy-0.19.0:\n",
      "      Successfully uninstalled kiwipiepy-0.19.0\n",
      "Successfully installed kiwipiepy-0.18.1 kiwipiepy-model-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install kiwipiepy==0.19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd479a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai # 0.28.0\n",
    "import re\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "# Kiwi 초기화\n",
    "kiwi = Kiwi(num_workers=0, model_path=None, load_default_dict=True, integrate_allomorph=True, model_type='sbg', typos=None, typo_cost_threshold=2.5)\n",
    "\n",
    "\"\"\"\n",
    "num_workers: 2 이상이면 단어 추출 및 형태소 분석에 멀티 코어를 활용하여 조금 더 빠른 속도로 분석을 진행할 수 있습니다.\n",
    "1인 경우 단일 코어만 활용합니다. num_workers가 0이면 현재 환경에서 사용가능한 모든 코어를 활용합니다.\n",
    "생략 시 기본값은 0입니다.\n",
    "model_path: 형태소 분석 모델이 있는 경로를 지정합니다. 생략시 kiwipiepy_model 패키지로부터 모델 경로를 불러옵니다.\n",
    "load_default_dict: 추가 사전을 로드합니다. 추가 사전은 위키백과의 표제어 타이틀로 구성되어 있습니다. 이 경우 로딩 및 분석 시간이 약간 증가하지만 다양한 고유명사를 좀 더 잘 잡아낼 수 있습니다. 분석 결과에 원치 않는 고유명사가 잡히는 것을 방지하려면 이를 False로 설정하십시오.\n",
    "integrate_allomorph: 어미 중, '아/어', '았/었'과 같이 동일하지만 음운 환경에 따라 형태가 달라지는 이형태들을 자동으로 통합합니다.\n",
    "model_type: 형태소 분석에 사용할 언어 모델을 지정합니다. 'knlm', \"sbg\" 중 하나를 선택할 수 있습니다. \"sbg\" 는 상대적으로 느리지만 먼 거리에 있는 형태소 간의 관계를 포착할 수 있습니다.\n",
    "typos: 형태소 분석 시 간단한 오타를 교정합니다. None으로 설정 시 교정을 수행하지 않습니다.\n",
    "typo_cost_threshold: 오타 교정을 허용할 최대 오타 비용을 설정합니다.\n",
    "\"\"\"\n",
    "\n",
    "# API 키 설정\n",
    "openai.api_key = \"sk-proj-nlhN73CnCzO3ShLYyCPuT3BlbkFJdzOuNYCbeHCwAhrhhh7p\"\n",
    "\n",
    "        \n",
    "######## 데이터 => src/v1/resoures/ 디렉토리 내부로 이동시켜서 불러오게 바꾸기\n",
    "pos_descriptions  = {\"NNG\"\t:\"일반 명사\",\n",
    "\"NNP\"\t:\"고유 명사\",\n",
    "\"NNB\"\t:\"의존 명사\",\n",
    "\"NR\"\t:\"수사\",\n",
    "\"NP\"\t:\"대명사\",\n",
    "\"VV\"\t:\"동사\",\n",
    "\"VV-R\"\t:\"동사(규칙)\",\n",
    "\"VV-I\"\t:\"동사(불규칙)\",\n",
    "\"VA\"\t:\"형용사\",\n",
    "\"VA-R\"\t:\"형용사(규칙)\",\n",
    "\"VA-I\"\t:\"형용사(불규칙)\",\n",
    "\"VX\"\t:\"보조 용언\",\n",
    "\"VX-R\"\t:\"보조 용언(규칙)\",\n",
    "\"VX-I\"\t:\"보조 용언(불규칙)\",\n",
    "\"VCP\"\t:\"긍정 지시사(이다)\",\n",
    "\"VCN\"\t:\"부정 지시사(아니다)\",\n",
    "\"MM\"\t:\"관형사\",\n",
    "\"MAG\"\t:\"일반 부사\",\n",
    "\"MAJ\"\t:\"접속 부사\",\n",
    "\"IC\"\t:\"감탄사\",\n",
    "\"JKS\"\t:\"주격 조사\",\n",
    "\"JKC\"\t:\"보격 조사\",\n",
    "\"JKG\"\t:\"관형격 조사\",\n",
    "\"JKO\"\t:\"목적격 조사\",\n",
    "\"JKB\"\t:\"부사격 조사\",\n",
    "\"JKV\"\t:\"호격 조사\",\n",
    "\"JKQ\"\t:\"인용격 조사\",\n",
    "\"JX\"\t:\"보조사\",\n",
    "\"JC\"\t:\"접속 조사\",\n",
    "\"EP\"\t:\"선어말 어미\",\n",
    "\"EF\"\t:\"종결 어미\",\n",
    "\"EC\"\t:\"연결 어미\",\n",
    "\"ETN\"\t:\"명사형 전성 어미\",\n",
    "\"ETM\"\t:\"관형형 전성 어미\",\n",
    "\"XPN\"\t:\"체언 접두사\",\n",
    "\"XSN\"\t:\"명사 파생 접미사\",\n",
    "\"XSV\"\t:\"동사 파생 접미사\",\n",
    "\"XSA\"\t:\"형용사 파생 접미사\",\n",
    "\"XSA-R\"\t:\"형용사 파생 접미사(규칙)\",\n",
    "\"XSA-I\"\t:\"형용사 파생 접미사(불규칙)\",\n",
    "\"XSM\"\t:\"부사 파생 접미사\",\n",
    "\"XR\"\t:\"어근\",\n",
    "\"SF\"\t:\"종결 부호(. ! ?)\",\n",
    "\"SP\"\t:\"구분 부호(, / : ;)\",\n",
    "\"SS\"\t:\"\"\"인용 부호 및 괄호(\" \" ( ) [ ] < > { } ― ‘ ’ “ ” ≪ ≫ 등)\"\"\",\n",
    "\"SSO\"\t:\"SS 중 여는 부호\",\n",
    "\"SSC\"\t:\"SS 중 닫는 부호\",\n",
    "\"SE\"\t:\"줄임표(…)\",\n",
    "\"SO\"\t:\"붙임표(- ~)\",\n",
    "\"SW\"\t:\"기타 특수 문자\",\n",
    "\"SL\"\t:\"알파벳(A-Z a-z)\",\n",
    "\"SH\"\t:\"한자\",\n",
    "\"SN\"\t:\"숫자(0-9)\",\n",
    "\"SB\"\t:\"순서 있는 글머리(가. 나. 1. 2. 가) 나) 등)*\",\n",
    "\"UN\"\t:\"분석 불능\",\n",
    "\"W_URL\"\t:\"URL 주소\",\n",
    "\"W_EMAIL\"\t:\"이메일 주소\",\n",
    "\"W_HASHTAG\"\t:\"해시태그(#abcd)\",\n",
    "\"W_MENTION\"\t:\"멘션(@abcd)\",\n",
    "\"W_SERIAL\"\t:\"일련번호(전화번호, 통장번호, IP주소 등)\",\n",
    "\"Z_CODA\"\t:\"덧붙은 받침\",\n",
    "\"USER0_4\"\t:\"사용자 정의 태그\"}\n",
    "\n",
    "\n",
    "\n",
    "# 문법 항목 리스트 생성\n",
    "\"\"\"\n",
    "\"/\" 로 끊어서 판단.\n",
    "품사번호 확인 후 형태가 같으면 해당 태그가 사용 됨.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "328fbe83",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'번호': 1,\n",
       "  '형태': '라고 합니다',\n",
       "  '품사': 'VCP+EC+VV+EF',\n",
       "  '의미': '((‘이다’, ‘아니다’의 어간이나 어미 ‘-으시-’ 뒤에 붙어)) ‘이라’, ‘아니라’의 어미 ‘-라’에 격 조사 ‘고’가 결합한 말. 간접적으로 인용됨을 나타낸다.'},\n",
       " {'번호': 2, '형태': '있어요', '품사': 'VA+EF', '의미': '문장 속에서 어떤 대상이 화제임을 나타내는 보조사'},\n",
       " {'번호': 3, '형태': '안', '품사': 'MAG', '의미': '부정이나 반대의 뜻을 나타내는 말'},\n",
       " {'번호': 4,\n",
       "  '형태': '에',\n",
       "  '품사': 'JKB',\n",
       "  '의미': '앞말이 처소의 부사어임을 나타내는 격 조사 또는 진행 방향의 부사어임을 나타내는 격 조사'},\n",
       " {'번호': 5,\n",
       "  '형태': '-았/었/였어요',\n",
       "  '품사': 'VV+EP+EF',\n",
       "  '의미': '어떤 행동이 과거에 이루어졌음을 나타내는 말.'},\n",
       " {'번호': 98, '형태': '에', '품사': 'JKB', '의미': '앞말이 시간의 부사어임을 나타내는 격 조사'},\n",
       " {'번호': 99, '형태': '에', '품사': 'JKB', '의미': '앞의 체언을 부사어가 되게 하는 조사'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammatical_items = [\n",
    "    {\n",
    "        \"번호\": 1,\n",
    "        \"형태\": '라고 합니다',\n",
    "        '품사': 'VCP+EC+VV+EF',\n",
    "        '의미': '((‘이다’, ‘아니다’의 어간이나 어미 ‘-으시-’ 뒤에 붙어)) ‘이라’, ‘아니라’의 어미 ‘-라’에 격 조사 ‘고’가 결합한 말. 간접적으로 인용됨을 나타낸다.',\n",
    "    },\n",
    "    {\n",
    "        '번호': 2,\n",
    "        '형태': '있어요',\n",
    "        '품사': 'VA+EF',\n",
    "        '의미': '문장 속에서 어떤 대상이 화제임을 나타내는 보조사',\n",
    "    },\n",
    "    {\n",
    "        '번호': 3,\n",
    "        '형태': '안',\n",
    "        '품사': 'MAG',\n",
    "        '의미': '부정이나 반대의 뜻을 나타내는 말',\n",
    "    },\n",
    "    {\n",
    "        '번호': 4,\n",
    "        '형태': '에',\n",
    "        '품사': 'JKB',\n",
    "        '의미': '앞말이 처소의 부사어임을 나타내는 격 조사 또는 진행 방향의 부사어임을 나타내는 격 조사',\n",
    "    },\n",
    "    {\n",
    "        '번호': 5,\n",
    "        '형태': '-았/었/였어요',\n",
    "        '품사': 'VV+EP+EF',\n",
    "        '의미': \"어떤 행동이 과거에 이루어졌음을 나타내는 말.\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        '번호': 98,\n",
    "        '형태': '에',\n",
    "        '품사': 'JKB',\n",
    "        '의미': '앞말이 시간의 부사어임을 나타내는 격 조사',\n",
    "    },\n",
    "    {\n",
    "        '번호': 99,\n",
    "        '형태': '에',\n",
    "        '품사': 'JKB',\n",
    "        '의미': '앞의 체언을 부사어가 되게 하는 조사',\n",
    "    },\n",
    "]\n",
    "\n",
    "grammatical_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0df4c38",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 로직컬 적으로 판단을 위해\n",
    " \n",
    "# 시간 명사\n",
    "time_nouns = {\n",
    "\"시간\", \"때\", \"시각\", \"분\", \"초\", \"어제\", \"오늘\", \"내일\", \"모레\", \"그제\", \"글피\", \"지난주\", \"이번주\", \"다음주\",\n",
    "\"월요일\", \"화요일\", \"수요일\", \"목요일\", \"금요일\", \"토요일\", \"일요일\", \"주말\", \"평일\", \"아침\", \"점심\", \"저녁\", \"밤\", \"새벽\", \"낮\",\n",
    "\"방금\", \"그때\", \"이때\", \"저때\", \"지금\", \"그동안\", \"이후\", \"이전\", \"지난달\", \"이번달\", \"다음달\", \"작년\", \"올해\", \"내년\",\n",
    "\"봄\", \"여름\", \"가을\", \"겨울\", \"어린 시절\", \"청소년기\", \"성인기\", \"노년기\", \"초\", \"중\", \"말\", \"첫날\", \"마지막 날\",\n",
    "\"전날\", \"이튿날\", \"사흘\", \"나흘\", \"닷새\", \"엿새\", \"일주일\", \"보름\", \"한 달\", \"두 달\", \"세 달\", \"석 달\", \"반년\", \"일년\", \"두 해\", \"세 해\",\n",
    "\"연초\", \"연말\", \"중순\", \"상반기\", \"하반기\", \"사계절\", \"1분기\", \"2분기\", \"3분기\", \"4분기\", \"10년\", \"세기\", \"밀레니엄\", \"대공황\",\n",
    "\"유년기\", \"사춘기\", \"청년기\", \"중년기\", \"노년기\", \"이전\", \"다음\", \"이후\", \"현재\", \"과거\", \"미래\", \"선사시대\", \"고대\", \"중세\", \"근세\", \"현대\",\n",
    "\"새벽 1시\", \"새벽 2시\", \"오전 3시\", \"오전 4시\", \"오후 5시\", \"오후 6시\", \"밤 7시\", \"밤 8시\", \"자정\", \"정오\", \n",
    "\"초반\", \"중반\", \"후반\", \"초기\", \"중기\", \"말기\", \"하루\", \"주중\", \"주간\", \"연중\", \"평생\", \"영원\", \"순간\", \"찰나\", \"잠시\", \"얼마간\", \n",
    "\"하루하루\", \"해마다\", \"계속\", \"영겁\", \"어느 날\", \"어느 순간\", \"동이 틀 무렵\", \"해질 녘\", \"밤중\", \"한낮\", \"정오\", \"이른 아침\", \"늦은 저녁\",\n",
    "\"초저녁\", \"심야\", \"한밤중\", \"말년\", \"초창기\", \"말미\", \"막바지\", \"오랜만\", \"잠깐\", \"순식간\", \"한순간\", \"짧은 시간\", \"긴 시간\",\n",
    "\"첫 번째\", \"두 번째\", \"세 번째\", \"네 번째\", \"다섯 번째\", \"처음\", \"마지막\", \"종반\", \"결말\", \"피날레\",\n",
    "\"20세기\", \"21세기\", \"100년\", \"200년\", \"천년\", \"십년\", \"반세기\", \"한 세대\", \"두 세대\", \"역사 속에서\", \"오래전\", \n",
    "\"아득한 옛날\",\"시간\", \"때\", \"시각\", \"분\", \"초\", \"어제\", \"오늘\", \"내일\", \"모레\", \"지난주\", \"이번주\", \"다음주\",\n",
    "\"월요일\", \"화요일\", \"수요일\", \"목요일\", \"금요일\", \"토요일\", \"일요일\", \"주말\", \"아침\", \"점심\", \"저녁\", \"밤\", \"새벽\", \"방금\", \"그때\", \"지난달\",\n",
    "\"이번달\", \"다음달\", \"작년\", \"올해\", \"내년\", \"저번\" , \"이번\", \"옛날\", \"새벽\",\"아침\",\"오전\",\"자정\",\"주\",\"오전\",\"백년\",\"십년\",\"일년\",\n",
    "\"오후\",\"오후 1시\",\"오후 2시\",\"오후 3시\",\"오후 4시\",\"오후 5시\",\"오후 6시\",\"오후 7시\",\"오후 8시\",\"오후 9시\",\"오후 10시\",\"오후 11시\",\"오후 12시\",\n",
    "\"오전\",\"오전 1시\",\"오전 2시\",\"오전 3시\",\"오전 4시\",\"오전 5시\",\"오전 6시\",\"오전 7시\",\"오전 8시\",\"오전 9시\",\"오전 10시\",\"오전 11시\",\"오전 12시\",\n",
    "\"밤\",\"밤 1시\",\"밤 2시\",\"밤 3시\",\"밤 4시\",\"밤 5시\",\"밤 6시\",\"밤 7시\",\"밤 8시\",\"밤 9시\",\"밤 10시\",\"밤 11시\",\"밤 12시\",\n",
    "\"낮\",\"낮 1시\",\"낮 2시\",\"낮 3시\",\"낮 4시\",\"낮 5시\",\"낮 6시\",\"낮 7시\",\"낮 8시\",\"낮 9시\",\"낮 10시\",\"낮 11시\",\"낮 12시\",\n",
    "\"봄에\",\"여름에\",\"가을에\",\"겨울에\",\"초봄에\",\"늦가을에\",\"초여름에\",\"한여름에\",\"연말에\",\"연초에\",\"연중에\",\"계절에\",\"새벽에\",\"아침에\",\"점심에\",\"저녁에\",\"밤에\",\"자정에\",\n",
    "\"정오에\",\"해질녘에\",\"동틀 무렵에\",\"오후에\",\"이른 아침에\",\"한낮에\",\"늦은 밤에\",\"내일\",\"모레\",\"다음 주에\",\"다음 달에\",\"내년에\",\"미래에\",\"앞으로\",\"곧\",\"장차\",\"머지않아\",\n",
    "\"훗날에\",\"언젠가\",\"장래에\",\"이후에\",\"곧바로\",\"차후에\",\"나중에\",\"몇 년 후에\",\"먼 훗날에\",\"지금\",\"현재\",\"이 시간에\",\"오늘\",\"요즘에\",\"요새\",\"금방\",\"방금\",\"당장\",\"오늘 아침에\",\n",
    "\"이번 주에\",\"올해\",\"이번 달에\",\"이번 학기에\",\"이번에\",\"이번 시기에\",\"최근에\",\"옛날\",\"옛적에\",\"예전에\",\"과거에\",\"지난달에\",\"작년에\",\"어제\",\"그제\",\"지난주에\",\"한참 전에\",\"몇 년 전에\",\n",
    "\"어릴 때\",\"유년 시절에\",\"어린 시절에\",\"사춘기 때\",\"중학교 때\",\"고등학교 때\",\"대학교 때\",\"어렸을 때\",\"이전에\",\"과거 어느 날\",\"한때\",\"초창기에\",\"초기에\",\"아득한 옛날에\"\n",
    "}\n",
    "\n",
    "# 수량 명사\n",
    "quantity_nouns = {\n",
    "    '한', '두', '세', '네', '다섯', '여섯', '일곱', '여덟', '아홉', '열', '백', '천', '만',\n",
    "    '개', '명', '번', '시간', '일', '주', '달', '년', '원', '킬로그램', '그램', '미터', '센티미터', '리터', '도'\n",
    "}\n",
    "\n",
    "place_nouns = {\n",
    "    # 장소 명사\n",
    "    \"집\", \"학교\", \"회사\", \"공원\", \"도서관\", \"식당\", \"병원\", \"은행\", \"시장\", \"백화점\",\n",
    "    \"마트\", \"극장\", \"역\", \"공항\", \"호텔\", \"카페\", \"레스토랑\", \"교실\", \"방\", \"거리\",\n",
    "    \"도로\", \"바다\", \"산\", \"섬\", \"도시\", \"나라\", \"지하철\", \"버스정류장\", \"주차장\",\n",
    "    \"화장실\", \"사무실\", \"교회\", \"성당\", \"절\", \"박물관\", \"미술관\", \"경찰서\", \"소방서\",\n",
    "    \"체육관\", \"운동장\", \"수영장\", \"고속도로\", \"터미널\", \"아파트\", \"빌딩\", \"건물\",\n",
    "    \"영화관\", \"놀이공원\", \"공연장\", \"전시장\", \"서점\", \"약국\", \"미용실\", \"음식점\",\n",
    "    \"카센터\", \"주유소\", \"헬스장\", \"노래방\", \"카페테리아\", \"식품점\", \"편의점\", \"슈퍼마켓\",\n",
    "    \"학교\", \"회사\", \"집\", \"교실\", \"강의실\", \"연구실\", \"실험실\", \"운전면허시험장\",\n",
    "    \"운전학원\", \"운동장\", \"놀이방\", \"어린이집\", \"유치원\", \"초등학교\", \"중학교\", \"고등학교\", \"대학교\",\"시골\"\n",
    "    \"집\",\"학교\",\"회사\",\"공원\",\"병원\",\"도서관\",\"식당\",\"극장\",\"서점\",\"카페\",\"시장\",\"백화점\",\"마트\",\"공장\",\"경찰서\",\"소방서\",\"은행\",\"우체국\",\"박물관\",\"미술관\",\"체육관\",\"공항\",\"호텔\",\"산\",\"바다\",\"강\",\"호수\",\"숲\",\"해변\",\"사막\",\"동굴\",\"계곡\",\"들판\",\"섬\",\"폭포\",\"초원\",\"역\",\"버스 정류장\",\"지하철역\",\"터미널\",\"항구\",\"주차장\",\"정류장\",\"고속도로\",\"톨게이트\",\n",
    "    \"아파트\",\"빌딩\",\"교회\",\"성당\",\"사찰\",\"궁전\",\"성\",\"운동장\",\"야구장\",\"축구장\",\"수영장\",\"놀이공원\",\"경기장\",\n",
    "    \"한국\",\"미국\",\"일본\",\"중국\",\"영국\",\"서울\",\"부산\",\"뉴욕\",\"런던\",\"파리\",\"베이징\",\"도쿄\",\"베를린\",\"로마\",\"시드니\",\n",
    "    \"화장실\",\"교실\",\"강의실\",\"운전면허시험장\",\"회의실\",\"사무실\",\"운전석\",\"부엌\",\"거실\",\"방\",\n",
    "\n",
    "    # 진행 방향을 나타내는 명사\n",
    "    \"앞\", \"뒤\", \"옆\", \"위\", \"아래\", \"안\", \"밖\", \"사이\", \"중간\", \"주변\", \"근처\",\n",
    "    \"오른쪽\", \"왼쪽\", \"동쪽\", \"서쪽\", \"남쪽\", \"북쪽\", \"내부\", \"외부\", \"방향\", \"쪽\",\n",
    "    \"방면\", \"코너\", \"목적지\", \"출발지\", \"도착지\", \"지점\", \"위치\", \"장소\", \"경로\",\n",
    "    \"길\", \"골목\", \"입구\", \"출구\", \"교차로\", \"사거리\", \"삼거리\", \"기차역\", \"버스터미널\",\n",
    "    \"항구\", \"맞은편\", \"정면\", \"후면\", \"상단\", \"하단\", \"중앙\", \"가운데\", \"주위\", \"둘레\",\n",
    "    \"바깥\", \"안쪽\", \"외곽\", \"부근\", \"접근\", \"도로\", \"차선\", \"차로\", \"이정표\", \"교차점\",\n",
    "    \"코앞\", \"뒤편\", \"옆쪽\", \"바로\", \"곧장\", \"직진\", \"우회전\", \"좌회전\", \"유턴\", \"골목길\",\n",
    "    \"샛길\", \"지름길\", \"고가도로\", \"지하도\", \"육교\", \"다리\", \"터널\", \"고개\", \"언덕\",\"쪽\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcf2bd10",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([Token(form='테스트', tag='NNG', start=0, len=3),\n",
       "   Token(form='텍스트', tag='NNG', start=4, len=3),\n",
       "   Token(form='이', tag='VCP', start=8, len=1),\n",
       "   Token(form='ᆸ니다', tag='EF', start=8, len=3),\n",
       "   Token(form='.', tag='SF', start=11, len=1)],\n",
       "  -33.727684020996094)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiwi.analyze(\"테스트 텍스트 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0929a93",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 함수 내에서 동기적으로 호출\n",
    "def chatgpt(text, matched_items, pna_token, now_token):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\", #gpt-4 ,gpt-4o-mini , gpt-4o, gpt-3.5-turbo\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            sentence: {text}\n",
    "            pna_token : {pna_token}\n",
    "            now_token : {now_token}\n",
    "            matched_items: {matched_items}\n",
    "\n",
    "            현재 나는 한국어 문장 태깅에서 판단하기 어려운 부분을 너에게 맡기려고 해.\n",
    "            sentence는 전체 문장이고, pna_token의 가운데인 now_token의 태깅을 판단해야해.\n",
    "            matched_items는 현재 태깅의 어려운 부분이야. 이 부분이 2가지 이상의 태깅이 되어있어.\n",
    "            matched_items의 번호가 몇번이 정답일지 판단해서 숫자로 정답만 알려줘\n",
    "            matched_items의 번호가 0번인 경우 nlp모델이 분류한 결과야 이게 맞을 수 있는데 나머지 번호가 틀렸다고 판단될 경우 0번으로 알려줘\n",
    "            그렇지 않은 경우 반드시 matched_items의 번호 중에서의 숫자만 알려줘.\n",
    "            반드시 설명하지말고 숫자만 알려줘.\n",
    "            \"\"\"\n",
    "        }],\n",
    "        stream=False,  # 스트리밍 비활성화\n",
    "    )\n",
    "\n",
    "    # 응답 처리\n",
    "    full_text = str(response['choices'][0]['message']['content'])\n",
    "    print(\"====GPT answer====\", full_text)\n",
    "\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28a86543",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "grammatical_items_dict = {item['번호']: item for item in grammatical_items} # 딕셔너리로 빨리 찾기\n",
    "# token_1 = grammatical_items_dict[n] # n번 태깅 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b349479a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m change_pos_descriptions \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mgrammatical_items\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrammatical_items\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrammatical_items\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m번호\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# 16번 태깅 찾기\u001b[39;00m\n\u001b[1;32m      2\u001b[0m grammatical_items_dict[\u001b[38;5;241m16\u001b[39m] \u001b[38;5;66;03m# n번 태깅 찾기\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "change_pos_descriptions = [grammatical_items[k] for k in range(len(grammatical_items)) if (grammatical_items[k]['번호']==16)][0] # 16번 태깅 찾기\n",
    "grammatical_items_dict[16] # n번 태깅 찾기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c707de",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# 사용하는 모델에 맞는 인코더 선택 (예: gpt-3.5-turbo)\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# 텍스트를 토큰으로 변환\n",
    "text = \"여기에 계산하고 싶은 텍스트를 입력하세요.\"\n",
    "tokens = encoding.encode(text)\n",
    "\n",
    "# 토큰의 개수 출력\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e42a87",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# #############\n",
    "# # \n",
    "# def pos_tag_print(results):\n",
    "#     output = []\n",
    "#     # 형태소 분석 결과와 문법 항목 매핑\n",
    "#     for tokens, score in results:\n",
    "#         for token in tokens:\n",
    "#             morpheme = token.form  # 형태소 (form)\n",
    "#             pos = token.tag        # 품사 태그 (tag)\n",
    "#             pos_desc = pos_descriptions.get(pos, '알 수 없음')\n",
    "#             matched_items = []\n",
    "#             for item in grammatical_items:\n",
    "#                 # 형태에서 '-'를 제거하고 '/'로 분리하여 각 형태소를 비교\n",
    "#                 item_forms = item['형태'].replace('-', '').split('/')\n",
    "#                 if morpheme in item_forms and pos == item['품사']:\n",
    "#                     matched_items.append(item)\n",
    "#             output.append({\n",
    "#                 'morpheme': morpheme,\n",
    "#                 'pos': pos,\n",
    "#                 'pos_desc': pos_desc,\n",
    "#                 'matched_items': matched_items\n",
    "#             })\n",
    "#     return output\n",
    "\n",
    "def pos_tag_print(results):\n",
    "    output = []\n",
    "    # 형태소 분석 결과와 문법 항목 매핑\n",
    "    for tokens, score in results:\n",
    "        for token in tokens:\n",
    "            morpheme = token.form  # 형태소 (form)\n",
    "            pos = token.tag        # 품사 태그 (tag)\n",
    "            start = token.start    # 형태소의 시작 인덱스\n",
    "            length = token.len     # 형태소의 길이\n",
    "            end = start + length   # 형태소의 끝 인덱스 계산\n",
    "            pos_desc = pos_descriptions.get(pos, '알 수 없음')\n",
    "            matched_items = []\n",
    "            for item in grammatical_items:\n",
    "                # 형태에서 '-'를 제거하고 '/'로 분리하여 각 형태소를 비교\n",
    "                item_forms = item['형태'].replace('-', '').split('/')\n",
    "                if morpheme in item_forms and pos == item['품사']:\n",
    "                    matched_items.append(item)\n",
    "            output.append({\n",
    "                'morpheme': morpheme,\n",
    "                'pos': pos,\n",
    "                'pos_desc': pos_desc,\n",
    "                'matched_items': matched_items,\n",
    "                'start': start,\n",
    "                'len': length,\n",
    "                'end': end\n",
    "            })\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11270e58",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#문장을 끊어서 판단\n",
    "def split_sentences(output): \n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for token in output: \n",
    "        sentence.append(token)\n",
    "        if token['pos'] in ['SF']: # 문장 구분: 종결 어미(EF)와 종결 부호(SF)를 기준으로 문장을 분리 # @@ 바꾸어야 할 지도.\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "    # 마지막 문장이 EF나 SF로 끝나지 않는 경우 처리\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def check_logic(sentence_tokens):\n",
    "    \n",
    "    output = all_text = sentence_tokens # GPT에 쓰임\n",
    "    assigned_indices = set()\n",
    "    \n",
    "    ### JKB 처리 (10번 11번)\n",
    "    for idx, token in enumerate(output):\n",
    "        if token['morpheme'] == '에' and token['pos'] == 'JKB':\n",
    "            assigned = False  # 번호가 할당되었는지 여부를 추적\n",
    "            # 앞의 토큰을 가져옵니다.\n",
    "            if idx > 0:\n",
    "                # '에' 앞의 가장 가까운 명사(N)를 찾아 시간 표현인지 확인\n",
    "                for back_idx in range(idx - 1, -1, -1):\n",
    "                    back_token = output[back_idx]\n",
    "                    # print(back_token)  # 디버깅용 출력\n",
    "                    if back_token['pos'].startswith('N'):\n",
    "                        print(back_token['morpheme'])  # 디버깅용 출력\n",
    "                        \n",
    "                        \n",
    "                        if back_token['morpheme'] in time_nouns:\n",
    "                            print(\"11번\", back_token['morpheme'])  # 디버깅용 출력\n",
    "                            # 시간 표현 단어를 찾았으므로 번호 11로 설정\n",
    "                            item11 = next((item for item in token['matched_items'] if item['번호'] == 11), None)\n",
    "                            if item11:\n",
    "                                token['matched_items'] = [item11]\n",
    "                                break  # 가장 가까운 N*를 찾았으므로 루프 종료\n",
    "\n",
    "                        if back_token['morpheme'] in place_nouns:\n",
    "                            print(\"10번\", back_token['morpheme'])  # 디버깅용 출력\n",
    "                            # 처소 및 진행 방향의 부사어 인지 판단하는 로직 추가\n",
    "                            item10 = next((item for item in token['matched_items'] if item['번호'] == 10), None)\n",
    "                            if item10:\n",
    "                                token['matched_items'] = [item10]\n",
    "                                break  # 가장 가까운 N*를 찾았으므로 루프 종료\n",
    "                        else:\n",
    "                            # 가장 가까운 명사가 시간이나 장소가 아니니 태깅 x\n",
    "                            break\n",
    "            else:\n",
    "                # 앞의 토큰이 없는 경우 번호를 할당하지 않음\n",
    "                pass\n",
    "            \n",
    "\n",
    "    ### '나/이나' (JC) 처리: 아이템 21번 태깅\n",
    "    for idx, token in enumerate(output):\n",
    "        if token['morpheme'] in ['나', '이나'] and token['pos'] == 'JC':\n",
    "            # 앞뒤 토큰을 확인합니다.\n",
    "            prev_token = output[idx - 1] if idx > 0 else None\n",
    "            next_token = output[idx + 1] if idx + 1 < len(output) else None\n",
    "            nnext_token = output[idx + 2] if idx + 2 < len(output) else None\n",
    "\n",
    "            if prev_token and next_token:\n",
    "                # 앞뒤 토큰의 품사가 명사(N*)인지 확인\n",
    "                if prev_token['pos'].startswith('N') and next_token['pos'].startswith('N') and (nnext_token['pos'].endswith('V') == False):\n",
    "                    # 번호 21번 항목을 가져옵니다.\n",
    "                    token_1 = grammatical_items_dict[21] # n번 태깅 찾기\n",
    "                    token['pos']= token_1[\"품사\"]\n",
    "                    token['pos_desc']= token_1[\"의미\"]\n",
    "                    token['matched_items'].append(token_1)\n",
    "        \n",
    "    ### '세요' (EF) 처리  17번 (강제로 찾게 만듦.)\n",
    "    for token in output:\n",
    "        if token['pos'] == 'EF' and token['morpheme'].endswith('세요'):\n",
    "\n",
    "            token_1 = token_1 = grammatical_items_dict[17] # n번 태깅 찾기\n",
    "            token['pos']= token_1[\"품사\"]\n",
    "            token['pos_desc']= token_1[\"의미\"]\n",
    "            token['matched_items'].append(token_1)\n",
    "    \n",
    "    # '수' + '밖' + '에' 패턴 병합 로직 추가\n",
    "    idx = 0\n",
    "    while idx < len(output) - 2:\n",
    "        prev_token = output[idx]\n",
    "        token = output[idx + 1]\n",
    "        next_token = output[idx + 2]\n",
    "        # '수'(NNB) + '밖'(NNG) + '에'(JKB) 패턴 확인\n",
    "        if (prev_token['morpheme'] == '수' and prev_token['pos'] == 'NNB' and\n",
    "            token['morpheme'] == '밖' and token['pos'] == 'NNG' and\n",
    "            next_token['morpheme'] == '에' and next_token['pos'] == 'JKB'):\n",
    "            # '밖' + '에'를 병합하여 '밖에'로 만듦\n",
    "            merged_token = {\n",
    "                'morpheme': token['morpheme'] + next_token['morpheme'],\n",
    "                'pos': token_1[\"품사\"],\n",
    "                'pos_desc': token_1[\"의미\"],\n",
    "                'matched_items': [token_1],\n",
    "                'start': token['start'],\n",
    "                'len': token['len'] + next_token['len'],\n",
    "                'end': token['start'] + token['len'] + next_token['len']\n",
    "            }\n",
    "            # 문법 항목 번호 24번 적용\n",
    "            item24 = grammatical_items_dict[24]  # 번호 24번 항목\n",
    "            if item24:\n",
    "                merged_token['matched_items'].append(item24)\n",
    "            # '수'는 그대로 두고 '밖'과 '에'를 병합된 토큰으로 대체\n",
    "            output = output[:idx + 1] + [merged_token] + output[idx + 3:]\n",
    "            # 인덱스 조정\n",
    "            idx += 1\n",
    "        else:\n",
    "            idx += 1\n",
    "\n",
    "            \n",
    "    ### 16번 태깅 '보' + '고' 패턴 병합 로직 추가\n",
    "    idx = 0\n",
    "    while idx < len(output) - 1:\n",
    "        token = output[idx]\n",
    "        next_token = output[idx + 1]\n",
    "        if token['morpheme'] == '보' and token['pos'] == 'VV' and next_token['morpheme'] == '고' and next_token['pos'] == 'EC':\n",
    "            token_1 = grammatical_items_dict[16] # n번 태깅 찾기\n",
    "            \n",
    "            print(token_1)\n",
    "            # '보' + '고'를 병합하여 '보고'로 만듦\n",
    "            merged_token = {\n",
    "                'morpheme': token['morpheme'] + next_token['morpheme'],\n",
    "                'pos': token_1[\"품사\"],\n",
    "                'pos_desc': token_1[\"의미\"],\n",
    "                'matched_items': [token_1],\n",
    "                'start': token['start'],\n",
    "                'len': token['len'] + next_token['len'],\n",
    "                'end': token['start'] + token['len'] + next_token['len']\n",
    "            }\n",
    "            # 기존 토큰을 삭제하고 병합된 토큰을 삽입\n",
    "            output = output[:idx] + [merged_token] + output[idx + 2:]\n",
    "            # 인덱스 조정\n",
    "            if idx > 0:\n",
    "                idx -= 1  # 병합 후 이전 위치로 이동하여 앞의 토큰과의 관계도 검사\n",
    "            else:\n",
    "                idx = 0\n",
    "        else:\n",
    "            idx += 1\n",
    "            \n",
    "    # N* N* N* 패턴에서 가운데 N이 '보고'인 경우 번호 16번 태깅 (강제로 찾게 만듦.)\n",
    "    for idx in range(1, len(output) - 1):\n",
    "        token = output[idx]\n",
    "        if token['pos'] == 'NNG' and token['morpheme'] == '보고':\n",
    "            prev_token = output[idx - 1]\n",
    "            next_token = output[idx + 1]\n",
    "            if prev_token['pos'].startswith('N') and next_token['pos'].startswith('N'):\n",
    "                # 번호 16으로 설정\n",
    "                token_1 = grammatical_items_dict[16] # n번 태깅 찾기\n",
    "                token['pos']= token_1[\"품사\"]\n",
    "                token['pos_desc']= token_1[\"의미\"]\n",
    "                token['matched_items'].append(token_1)\n",
    "\n",
    "\n",
    "    # gpt 이용 부문.\n",
    "    # @@ 여기서 gpt가 답을 고르지 못한 경우 None 태그를 만들어서 이 경우엔 기본 태그가 나오게 하자.\n",
    "    # 최종, 태그가 2개 이상 있는 경우 해당 태그를 llm모델에 맡겨서 뭐가 맞는지 판단하게 함.\n",
    "    for idx, token in enumerate(output):\n",
    "        if len(token[\"matched_items\"]) >= 2:\n",
    "            # 이전 토큰과 다음 토큰을 가져옵니다.\n",
    "            pre_token = output[idx - 1][\"morpheme\"] if idx > 0 else ''\n",
    "            now_token = token[\"morpheme\"]\n",
    "            after_token = output[idx + 1][\"morpheme\"] if idx + 1 < len(output) else ''\n",
    "\n",
    "            # 문장 전체 텍스트를 재구성합니다.\n",
    "            sentence_text = ''.join(tok['morpheme'] for tok in output)\n",
    "\n",
    "            # try:\n",
    "            #     # GPT 함수 호출\n",
    "            #     token['matched_items'].insert(0,{'번호': 0,'형태': token['morpheme'],'품사': token['pos'],'의미': token['pos_desc']}) # 기존 형태의 품사(nlp가 분류한 더 큰 집합[분류]의 품사)를 넣고 비교\n",
    "            #     print(token['matched_items'])\n",
    "            #     gpt_answer = chatgpt(sentence_text, token[\"matched_items\"], pre_token + now_token + after_token, now_token)\n",
    "                \n",
    "            #     correct_tag = int(re.findall(r'\\d+', gpt_answer)[0]) # GPT 응답에서 숫자 추출\n",
    "            #     print(correct_tag,\"correct_tag\")\n",
    "\n",
    "            #     item = next((item for item in token['matched_items'] if item['번호'] == correct_tag), None)\n",
    "            #     if item:\n",
    "            #         token['matched_items'] = [item]\n",
    "\n",
    "            #     print(\"llm사용됨\", sentence_text)\n",
    "            #     print(\"정답으로 만든 태그\", correct_tag, token[\"matched_items\"])\n",
    "\n",
    "            # except Exception as e:\n",
    "            #     correct_tag = 0\n",
    "            #     print(\"GPT오류\", e)\n",
    "            #     pass    \n",
    "            \n",
    "            if correct_tag == 0: # 0번의 경우 그대로 태깅\n",
    "                token['matched_items'] = []\n",
    "            else:\n",
    "                item = next((item for item in token['matched_items'] if item['번호'] == correct_tag), None)\n",
    "                if item:\n",
    "                    token['matched_items'] = [item]\n",
    "            \n",
    "        else:\n",
    "            # 태그가 1개인 경우 패스 \n",
    "            pass\n",
    "        \n",
    "    # 최종 결과 출력\n",
    "    for token in output:\n",
    "        morpheme = token['morpheme']\n",
    "        pos = token['pos']\n",
    "        pos_desc = token['pos_desc']\n",
    "        start = token['start']\n",
    "        length = token['len']\n",
    "        matched_items = token['matched_items']\n",
    "\n",
    "        if matched_items and (matched_items[0]['번호'] != 0):\n",
    "            for item in matched_items:\n",
    "                print(f\"형태소 '{morpheme}' (위치: {start}, 길이: {length}, 품사: {pos} - {pos_desc})는 문법 항목 번호 {item['번호']}에 해당합니다: {item['의미']}\")\n",
    "        else:\n",
    "            print(f\"형태소 '{morpheme}' (위치: {start}, 길이: {length}, 품사: {pos} - {pos_desc})\")\n",
    "            \n",
    "    return output  # 수정된 output 리스트 반환\"\"\"\n",
    "\n",
    "def main(text):\n",
    "    # pos_tag_print 함수 호출 # 형태소 분석 수행\n",
    "    output = pos_tag_print(results = kiwi.analyze(text))\n",
    "    # 문장 단위로 분리 @@ => 이붑분 kiwi 분석기가 있다했음\n",
    "    \n",
    "    sentences = split_sentences(output)\n",
    "    # 각 문장별로 처리하고 결과를 합침\n",
    "\n",
    "    final_output = []\n",
    "    for sentence_tokens in sentences:\n",
    "        processed_sentence = check_logic(sentence_tokens)\n",
    "        final_output.extend(processed_sentence)\n",
    "        \n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8579d859",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연세\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 잘 틀리는 것 예시 잘 못하는\u001b[39;00m\n\u001b[1;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m우리 할아버지는 연세에 비하면 젊어 보이세요.\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m햄버거에 비하면 샌드위치는 칼로리가 낮은 편이에요.\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m final_output\n",
      "Cell \u001b[0;32mIn[22], line 231\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    229\u001b[0m final_output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence_tokens \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[0;32m--> 231\u001b[0m     processed_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_logic\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     final_output\u001b[38;5;241m.\u001b[39mextend(processed_sentence)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_output\n",
      "Cell \u001b[0;32mIn[22], line 79\u001b[0m, in \u001b[0;36mcheck_logic\u001b[0;34m(sentence_tokens)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEF\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m token[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmorpheme\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m세요\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m         token_1 \u001b[38;5;241m=\u001b[39m token_1 \u001b[38;5;241m=\u001b[39m \u001b[43mgrammatical_items_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m17\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# n번 태깅 찾기\u001b[39;00m\n\u001b[1;32m     80\u001b[0m         token[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m token_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m품사\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     81\u001b[0m         token[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos_desc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m token_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m의미\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 17"
     ]
    }
   ],
   "source": [
    "# 잘 틀리는 것 예시 잘 못하는\n",
    "\n",
    "text = \"\"\"\n",
    "우리 할아버지는 연세에 비하면 젊어 보이세요.\n",
    "햄버거에 비하면 샌드위치는 칼로리가 낮은 편이에요.\n",
    "\"\"\"\n",
    "\n",
    "final_output = main(text)\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80f8d178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서재\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'correct_tag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 2번 예시\u001b[39;00m\n\u001b[1;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m책은 서재에 있어요.\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m거거엔 뭐가 있어요?\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m집 근처에 예쁜 카페가 있어요.\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m여기에서 버스를 탈 수 있는 정류장이 있어요?\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 231\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    229\u001b[0m final_output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence_tokens \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[0;32m--> 231\u001b[0m     processed_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_logic\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     final_output\u001b[38;5;241m.\u001b[39mextend(processed_sentence)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_output\n",
      "Cell \u001b[0;32mIn[22], line 193\u001b[0m, in \u001b[0;36mcheck_logic\u001b[0;34m(sentence_tokens)\u001b[0m\n\u001b[1;32m    170\u001b[0m sentence_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tok[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmorpheme\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m output)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m#     # GPT 함수 호출\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m#     token['matched_items'].insert(0,{'번호': 0,'형태': token['morpheme'],'품사': token['pos'],'의미': token['pos_desc']}) # 기존 형태의 품사(nlp가 분류한 더 큰 집합[분류]의 품사)를 넣고 비교\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m#     print(\"GPT오류\", e)\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m#     pass    \u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcorrect_tag\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# 0번의 경우 그대로 태깅\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     token[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatched_items\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'correct_tag' is not defined"
     ]
    }
   ],
   "source": [
    "# 2번 예시\n",
    "text = \"\"\"\n",
    "책은 서재에 있어요.\n",
    "거거엔 뭐가 있어요?\n",
    "집 근처에 예쁜 카페가 있어요.\n",
    "여기에서 버스를 탈 수 있는 정류장이 있어요?\n",
    "\"\"\"\n",
    "final_output = main(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a55c0b1a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 '자기' (위치: 1, 길이: 2, 품사: NP - 대명사)\n",
      "형태소 '는' (위치: 3, 길이: 1, 품사: JX - 보조사)\n",
      "형태소 '절대' (위치: 5, 길이: 2, 품사: MAG - 일반 부사)\n",
      "형태소 '범인' (위치: 8, 길이: 2, 품사: NNG - 일반 명사)\n",
      "형태소 '이' (위치: 10, 길이: 1, 품사: JKC - 보격 조사)\n",
      "형태소 '아니' (위치: 12, 길이: 2, 품사: VCN - 부정 지시사(아니다))\n",
      "형태소 '라고' (위치: 14, 길이: 2, 품사: EC - 연결 어미)\n",
      "형태소 '주장' (위치: 17, 길이: 2, 품사: NNG - 일반 명사)\n",
      "형태소 '하' (위치: 19, 길이: 1, 품사: XSV - 동사 파생 접미사)\n",
      "형태소 'ᆫ다' (위치: 19, 길이: 2, 품사: EF - 종결 어미)\n",
      "형태소 '.' (위치: 21, 길이: 1, 품사: SF - 종결 부호(. ! ?))\n",
      "형태소 '저' (위치: 23, 길이: 1, 품사: NP - 대명사)\n",
      "형태소 '는' (위치: 24, 길이: 1, 품사: JX - 보조사)\n",
      "형태소 '김민수' (위치: 26, 길이: 3, 품사: NNP - 고유 명사)\n",
      "형태소 '이' (위치: 29, 길이: 0, 품사: VCP - 긍정 지시사(이다))\n",
      "형태소 '라고' (위치: 29, 길이: 2, 품사: EC - 연결 어미)\n",
      "형태소 '하' (위치: 32, 길이: 1, 품사: VV - 동사)\n",
      "형태소 'ᆸ니다' (위치: 32, 길이: 3, 품사: EF - 종결 어미)\n",
      "형태소 '.' (위치: 35, 길이: 1, 품사: SF - 종결 부호(. ! ?))\n",
      "형태소 '이' (위치: 37, 길이: 1, 품사: MM - 관형사)\n",
      "형태소 '식물' (위치: 39, 길이: 2, 품사: NNG - 일반 명사)\n",
      "형태소 '은' (위치: 41, 길이: 1, 품사: JX - 보조사)\n",
      "형태소 '선인장' (위치: 43, 길이: 3, 품사: NNG - 일반 명사)\n",
      "형태소 '이' (위치: 46, 길이: 1, 품사: VCP - 긍정 지시사(이다))\n",
      "형태소 '라고' (위치: 47, 길이: 2, 품사: EC - 연결 어미)\n",
      "형태소 '하' (위치: 50, 길이: 1, 품사: VV - 동사)\n",
      "형태소 'ᆸ니다' (위치: 50, 길이: 3, 품사: EF - 종결 어미)\n",
      "형태소 '.' (위치: 53, 길이: 1, 품사: SF - 종결 부호(. ! ?))\n",
      "형태소 '이곳' (위치: 55, 길이: 2, 품사: NP - 대명사)\n",
      "형태소 '은' (위치: 57, 길이: 1, 품사: JX - 보조사)\n",
      "형태소 '아름답' (위치: 59, 길이: 4, 품사: VA-I - 형용사(불규칙))\n",
      "형태소 '은' (위치: 62, 길이: 1, 품사: ETM - 관형형 전성 어미)\n",
      "형태소 '풍경' (위치: 64, 길이: 2, 품사: NNG - 일반 명사)\n",
      "형태소 '으로' (위치: 66, 길이: 2, 품사: JKB - 부사격 조사)\n",
      "형태소 '유명' (위치: 69, 길이: 2, 품사: NNG - 일반 명사)\n",
      "형태소 '하' (위치: 71, 길이: 1, 품사: XSA - 형용사 파생 접미사)\n",
      "형태소 'ᆫ' (위치: 71, 길이: 1, 품사: ETM - 관형형 전성 어미)\n",
      "형태소 '제주도' (위치: 73, 길이: 3, 품사: NNP - 고유 명사)\n",
      "형태소 '이' (위치: 76, 길이: 0, 품사: VCP - 긍정 지시사(이다))\n",
      "형태소 '라고' (위치: 76, 길이: 2, 품사: EC - 연결 어미)\n",
      "형태소 '하' (위치: 79, 길이: 1, 품사: VV - 동사)\n",
      "형태소 'ᆸ니다' (위치: 79, 길이: 3, 품사: EF - 종결 어미)\n",
      "형태소 '.' (위치: 82, 길이: 1, 품사: SF - 종결 부호(. ! ?))\n",
      "형태소 '저' (위치: 84, 길이: 1, 품사: MM - 관형사)\n",
      "형태소 '책' (위치: 86, 길이: 1, 품사: NNG - 일반 명사)\n",
      "형태소 '은' (위치: 87, 길이: 1, 품사: JX - 보조사)\n",
      "형태소 '올해' (위치: 89, 길이: 2, 품사: NNG - 일반 명사)\n",
      "형태소 '의' (위치: 91, 길이: 1, 품사: JKG - 관형격 조사)\n",
      "형태소 '베스트셀러' (위치: 93, 길이: 5, 품사: NNG - 일반 명사)\n",
      "형태소 '이' (위치: 98, 길이: 0, 품사: VCP - 긍정 지시사(이다))\n",
      "형태소 '라고' (위치: 98, 길이: 2, 품사: EC - 연결 어미)\n",
      "형태소 '하' (위치: 101, 길이: 1, 품사: VV - 동사)\n",
      "형태소 'ᆸ니다' (위치: 101, 길이: 3, 품사: EF - 종결 어미)\n",
      "형태소 '.' (위치: 104, 길이: 1, 품사: SF - 종결 부호(. ! ?))\n"
     ]
    }
   ],
   "source": [
    "# 1번 예시\n",
    "text = \"\"\"\n",
    "자기는 절대 범인이 아니라고 주장한다.\n",
    "저는 김민수라고 합니다.\n",
    "이 식물은 선인장이라고 합니다.\n",
    "이곳은 아름다운 풍경으로 유명한 제주도라고 합니다.\n",
    "저 책은 올해의 베스트셀러라고 합니다.\n",
    "\"\"\"\n",
    "final_output = main(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80ef421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc731a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659015db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf7198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr_tag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
